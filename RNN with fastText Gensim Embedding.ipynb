{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with RNN and `fastText` Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to build RNN model with embedding `fastText`. Let's first load some required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk, re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from datetime import datetime\n",
    "from gensim.models import *\n",
    "import logging\n",
    "import time\n",
    "from rnn_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with our previous RNN model and `GloVe`, we will load data and clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/labeledTrainData.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning data\n",
    "\n",
    "After finishing loading the dataset, we will now define a function <span style=\"color:blue; font-family:Courier\"> format_train_review</span> ( in `rnn_utils` file) to clean up our data. This function will cut the review longer than our maximal length and looking up index for each word in our `word_list`. Padding will be done after we are done cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our saved `word_list` and `word_vector` to prepare for the clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_word_list = np.load('./data/word_list_gensim_fT.npy')\n",
    "load_word_vector = np.load('./data/word_vector_gensim_fT.npy')\n",
    "load_word_list = load_word_list.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will loop through all reviews in our dataset and call the function <span style=\"color:blue; font-family:Courier\"> format_train_review</span> to clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 3.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 230\n",
    "train_seq = []\n",
    "tic = time.time()\n",
    "for review in train.review:\n",
    "    f = format_train_review(train_review = review, max_seq_len = max_seq_len, word_list = load_word_list)\n",
    "    train_seq.append(f)\n",
    "time = np.round((time.time() - tic)/60)\n",
    "print(\"Processing time: {} minutes.\".format(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of review after formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   10,    16,     6,   366,     4,  2068,    37,  1204,  2183,\n",
       "        1337,     1,  1301,    26,     2,   106,   371,     1, 24801,\n",
       "         383,    28,     3,   726,  2710,    40,  3156,     5,   816,\n",
       "       10481,    10,    16,     6,     3,   978,    68,   699,    71,\n",
       "          49,    41,     7,     1,   679], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews truncating\n",
    "\n",
    "This will be the same when we do it for `word2vec` RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of review 9th: 230\n",
      "\n",
      "Total number of reviews: 25000\n"
     ]
    }
   ],
   "source": [
    "train_pad = pad_sequences(train_seq, maxlen = max_seq_len, padding='pre')\n",
    "print(\"Length of review 9th: {}\\n\".format(len(train_pad[9])))\n",
    "print(\"Total number of reviews: {}\".format(len(train_pad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from output below that review 9th has been padded with zeros at the beginning because it isn't long enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 9th after padding: \n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0    10    16     6\n",
      "   366     4  2068    37  1204  2183  1337     1  1301    26     2   106\n",
      "   371     1 24801   383    28     3   726  2710    40  3156     5   816\n",
      " 10481    10    16     6     3   978    68   699    71    49    41     7\n",
      "     1   679]\n"
     ]
    }
   ],
   "source": [
    "print(\"Review 9th after padding: \\n{}\".format(train_pad[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data\n",
    "\n",
    "We will split data into 3 parts: training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_test: (1984, 230)\n",
      "Shape of y_test: (1984,)\n"
     ]
    }
   ],
   "source": [
    "x_test = train_pad[0:1984]\n",
    "y_test = train.sentiment[0:1984]\n",
    "print(\"Shape of x_test: \"+ str(x_test.shape))\n",
    "print(\"Shape of y_test: \"+ str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x_train: (19563, 230)\n",
      "Length of y_train: (19563,) \n",
      "\n",
      "Shape of x_valid: (3453, 230)\n",
      "Shape of y_valid: (3453,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train_pad[1984:], \n",
    "                                                    train.sentiment[1984:], \n",
    "                                                    test_size = 0.15, \n",
    "                                                    random_state = 789)\n",
    "\n",
    "print(\"Length of x_train: \"+ str(x_train.shape))\n",
    "print(\"Length of y_train: \"+ str(y_train.shape) +\" \\n\")\n",
    "print(\"Shape of x_valid: \"+ str(x_valid.shape))\n",
    "print(\"Shape of y_valid: \"+ str(y_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches: 305\n",
      "\n",
      "Number of validation batches: 53\n",
      "\n",
      "Number of test batches: 31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "mini_batches_train = mini_batch(x_train, y_train, batch_size)\n",
    "mini_batches_valid = mini_batch(x_valid, y_valid, batch_size)\n",
    "mini_batches_test = mini_batch(x_test, y_test, batch_size)\n",
    "print(\"Number of train batches: {}\\n\".format(len(mini_batches_train)))\n",
    "print(\"Number of validation batches: {}\\n\".format(len(mini_batches_valid)))\n",
    "print(\"Number of test batches: {}\\n\".format(len(mini_batches_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Graph & Embeddings\n",
    "\n",
    "Values we used here are the same with our RNN with `GloVe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_words = len(load_word_list)\n",
    "embed_size = 50\n",
    "num_layers = 1\n",
    "lstm_size = 64\n",
    "n_epochs = 80\n",
    "prob = 0.5\n",
    "seq_len = 230\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build TensorGraph\n",
    "\n",
    "The only difference here is that we will use `load_word_vector` as our embedding vector which created as a result of learning embedding with `Gensim fastText` before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # Define Placeholders\n",
    "    tf_x = tf.placeholder(dtype = tf.int32, shape = (batch_size, seq_len), name = \"tf_x\")\n",
    "    tf_y = tf.placeholder(dtype = tf.float32, shape = (batch_size), name = \"tf_y\")\n",
    "    tf_keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    # Create Embedded layer\n",
    "    embedding = tf.nn.embedding_lookup(tf.cast(load_word_vector, tf.float32), tf_x, name='embedding')\n",
    "\n",
    "    # Define LSTM cells\n",
    "    drop_prob = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_size), output_keep_prob=tf_keep_prob)\n",
    "    lstm_cells = tf.contrib.rnn.MultiRNNCell([drop_prob] * num_layers)\n",
    "\n",
    "    # Set Initial state\n",
    "    init_state = lstm_cells.zero_state(batch_size, tf.float32)\n",
    "    lstm_outputs, final_state = tf.nn.dynamic_rnn(lstm_cells, embedding, initial_state=init_state)\n",
    "    \n",
    "    logits = tf.squeeze(tf.layers.dense(inputs=lstm_outputs[:,-1], units = 1, activation=None, name = 'logits'))\n",
    "    y_prob = tf.nn.sigmoid(logits, name = 'probabilities')\n",
    "    \n",
    "    predictions = {'probabilities': y_prob,\n",
    "                   'labels' : tf.cast(tf.round(y_prob), tf.int32,name='labels')}\n",
    "    # Cost\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels = tf_y))\n",
    "    tf.summary.scalar('cost', cost)\n",
    "    \n",
    "    # Optimizer\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.1\n",
    "    learning_rt = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           1000, 0.96, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rt)\n",
    "    train_op = optimizer.minimize(cost, name = 'train_op')\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.round(y_prob), tf_y)\n",
    "    acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar('accuracy', acc)\n",
    "    \n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RNN model\n",
    "\n",
    "It's time to train the model. Here we will build single layer RNN with 64 LSTM hidden units. The output activation function will be sigmoid function as we only need `1` (for positive review) or `0` (negative review).\n",
    "\n",
    "Changes in the accuracy and loss can be monitored via TensorBoard. Later when the training is done, I will display the screenshots of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/80 | Train loss: 0.5945 | Train accuracy: 0.6406\n",
      "Epoch: 1/80 | Validation loss: 0.5668 | Validation accuracy: 0.7500\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_1.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 175\n",
      "Epoch: 2/80 | Train loss: 0.4950 | Train accuracy: 0.7656\n",
      "Epoch: 2/80 | Validation loss: 0.4356 | Validation accuracy: 0.7969\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_2.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 173\n",
      "Epoch: 3/80 | Train loss: 0.5239 | Train accuracy: 0.6875\n",
      "Epoch: 3/80 | Validation loss: 0.4325 | Validation accuracy: 0.7812\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_3.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 174\n",
      "Epoch: 4/80 | Train loss: 0.5376 | Train accuracy: 0.7031\n",
      "Epoch: 4/80 | Validation loss: 0.4367 | Validation accuracy: 0.8281\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_4.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 184\n",
      "Epoch: 5/80 | Train loss: 0.4314 | Train accuracy: 0.8438\n",
      "Epoch: 5/80 | Validation loss: 0.3952 | Validation accuracy: 0.7812\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_5.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 173\n",
      "Epoch: 6/80 | Train loss: 0.4344 | Train accuracy: 0.8125\n",
      "Epoch: 6/80 | Validation loss: 0.3498 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_6.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 173\n",
      "Epoch: 7/80 | Train loss: 0.3995 | Train accuracy: 0.7969\n",
      "Epoch: 7/80 | Validation loss: 0.3509 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_7.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 178\n",
      "Epoch: 8/80 | Train loss: 0.3645 | Train accuracy: 0.8125\n",
      "Epoch: 8/80 | Validation loss: 0.3483 | Validation accuracy: 0.8438\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_8.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 174\n",
      "Epoch: 9/80 | Train loss: 0.4244 | Train accuracy: 0.7969\n",
      "Epoch: 9/80 | Validation loss: 0.3027 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_9.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 175\n",
      "Epoch: 10/80 | Train loss: 0.3993 | Train accuracy: 0.8438\n",
      "Epoch: 10/80 | Validation loss: 0.2986 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_10.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 175\n",
      "Epoch: 11/80 | Train loss: 0.4389 | Train accuracy: 0.8125\n",
      "Epoch: 11/80 | Validation loss: 0.3010 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_11.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 178\n",
      "Epoch: 12/80 | Train loss: 0.3369 | Train accuracy: 0.8125\n",
      "Epoch: 12/80 | Validation loss: 0.2833 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_12.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 199\n",
      "Epoch: 13/80 | Train loss: 0.3624 | Train accuracy: 0.8438\n",
      "Epoch: 13/80 | Validation loss: 0.2892 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_13.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 199\n",
      "Epoch: 14/80 | Train loss: 0.3796 | Train accuracy: 0.8125\n",
      "Epoch: 14/80 | Validation loss: 0.2947 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_14.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 189\n",
      "Epoch: 15/80 | Train loss: 0.3882 | Train accuracy: 0.8281\n",
      "Epoch: 15/80 | Validation loss: 0.2578 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_15.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 186\n",
      "Epoch: 16/80 | Train loss: 0.3270 | Train accuracy: 0.8281\n",
      "Epoch: 16/80 | Validation loss: 0.2964 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_16.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 196\n",
      "Epoch: 17/80 | Train loss: 0.2928 | Train accuracy: 0.8906\n",
      "Epoch: 17/80 | Validation loss: 0.2779 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_17.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 180\n",
      "Epoch: 18/80 | Train loss: 0.3334 | Train accuracy: 0.8594\n",
      "Epoch: 18/80 | Validation loss: 0.2626 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_18.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 181\n",
      "Epoch: 19/80 | Train loss: 0.3136 | Train accuracy: 0.8750\n",
      "Epoch: 19/80 | Validation loss: 0.2750 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_19.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 203\n",
      "Epoch: 20/80 | Train loss: 0.3876 | Train accuracy: 0.8281\n",
      "Epoch: 20/80 | Validation loss: 0.2683 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_20.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 180\n",
      "Epoch: 21/80 | Train loss: 0.2624 | Train accuracy: 0.8906\n",
      "Epoch: 21/80 | Validation loss: 0.3001 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_21.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 183\n",
      "Epoch: 22/80 | Train loss: 0.2819 | Train accuracy: 0.8438\n",
      "Epoch: 22/80 | Validation loss: 0.2734 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_22.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 212\n",
      "Epoch: 23/80 | Train loss: 0.3066 | Train accuracy: 0.8438\n",
      "Epoch: 23/80 | Validation loss: 0.2669 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_23.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 182\n",
      "Epoch: 24/80 | Train loss: 0.3612 | Train accuracy: 0.8125\n",
      "Epoch: 24/80 | Validation loss: 0.2284 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_24.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 179\n",
      "Epoch: 25/80 | Train loss: 0.2724 | Train accuracy: 0.8750\n",
      "Epoch: 25/80 | Validation loss: 0.2392 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_25.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 233\n",
      "Epoch: 26/80 | Train loss: 0.2649 | Train accuracy: 0.8750\n",
      "Epoch: 26/80 | Validation loss: 0.2047 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_26.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 232\n",
      "Epoch: 27/80 | Train loss: 0.2601 | Train accuracy: 0.8594\n",
      "Epoch: 27/80 | Validation loss: 0.2685 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_27.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 199\n",
      "Epoch: 28/80 | Train loss: 0.2168 | Train accuracy: 0.9219\n",
      "Epoch: 28/80 | Validation loss: 0.2569 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_28.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 289\n",
      "Epoch: 29/80 | Train loss: 0.2437 | Train accuracy: 0.9062\n",
      "Epoch: 29/80 | Validation loss: 0.2693 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_29.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 249\n",
      "Epoch: 30/80 | Train loss: 0.2979 | Train accuracy: 0.8438\n",
      "Epoch: 30/80 | Validation loss: 0.2851 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_30.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 220\n",
      "Epoch: 31/80 | Train loss: 0.2967 | Train accuracy: 0.8906\n",
      "Epoch: 31/80 | Validation loss: 0.2448 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_31.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 188\n",
      "Epoch: 32/80 | Train loss: 0.2405 | Train accuracy: 0.9062\n",
      "Epoch: 32/80 | Validation loss: 0.2480 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_32.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 182\n",
      "Epoch: 33/80 | Train loss: 0.2356 | Train accuracy: 0.9062\n",
      "Epoch: 33/80 | Validation loss: 0.2357 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_33.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 181\n",
      "Epoch: 34/80 | Train loss: 0.2549 | Train accuracy: 0.9219\n",
      "Epoch: 34/80 | Validation loss: 0.2408 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_34.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 186\n",
      "Epoch: 35/80 | Train loss: 0.1951 | Train accuracy: 0.8906\n",
      "Epoch: 35/80 | Validation loss: 0.4713 | Validation accuracy: 0.8125\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_35.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 184\n",
      "Epoch: 36/80 | Train loss: 0.3304 | Train accuracy: 0.8281\n",
      "Epoch: 36/80 | Validation loss: 0.2482 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_36.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 177\n",
      "Epoch: 37/80 | Train loss: 0.3195 | Train accuracy: 0.8594\n",
      "Epoch: 37/80 | Validation loss: 0.2589 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_37.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 210\n",
      "Epoch: 38/80 | Train loss: 0.2186 | Train accuracy: 0.8750\n",
      "Epoch: 38/80 | Validation loss: 0.2686 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_38.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 202\n",
      "Epoch: 39/80 | Train loss: 0.2873 | Train accuracy: 0.8750\n",
      "Epoch: 39/80 | Validation loss: 0.2786 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_39.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 186\n",
      "Epoch: 40/80 | Train loss: 0.2478 | Train accuracy: 0.8750\n",
      "Epoch: 40/80 | Validation loss: 0.2833 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_40.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 186\n",
      "Epoch: 41/80 | Train loss: 0.1973 | Train accuracy: 0.9219\n",
      "Epoch: 41/80 | Validation loss: 0.3299 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_41.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 195\n",
      "Epoch: 42/80 | Train loss: 0.2184 | Train accuracy: 0.9531\n",
      "Epoch: 42/80 | Validation loss: 0.2549 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_42.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 182\n",
      "Epoch: 43/80 | Train loss: 0.2459 | Train accuracy: 0.8594\n",
      "Epoch: 43/80 | Validation loss: 0.2329 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_43.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 180\n",
      "Epoch: 44/80 | Train loss: 0.1803 | Train accuracy: 0.9219\n",
      "Epoch: 44/80 | Validation loss: 0.2653 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_44.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 204\n",
      "Epoch: 45/80 | Train loss: 0.2313 | Train accuracy: 0.9375\n",
      "Epoch: 45/80 | Validation loss: 0.2887 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_45.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 185\n",
      "Epoch: 46/80 | Train loss: 0.2440 | Train accuracy: 0.9219\n",
      "Epoch: 46/80 | Validation loss: 0.2623 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_46.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 188\n",
      "Epoch: 47/80 | Train loss: 0.2181 | Train accuracy: 0.9062\n",
      "Epoch: 47/80 | Validation loss: 0.2596 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_47.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 219\n",
      "Epoch: 48/80 | Train loss: 0.2146 | Train accuracy: 0.8906\n",
      "Epoch: 48/80 | Validation loss: 0.2185 | Validation accuracy: 0.9375\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_48.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 191\n",
      "Epoch: 49/80 | Train loss: 0.2319 | Train accuracy: 0.8906\n",
      "Epoch: 49/80 | Validation loss: 0.2568 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_49.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 205\n",
      "Epoch: 50/80 | Train loss: 0.1841 | Train accuracy: 0.9062\n",
      "Epoch: 50/80 | Validation loss: 0.3121 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_50.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 188\n",
      "Epoch: 51/80 | Train loss: 0.1918 | Train accuracy: 0.9219\n",
      "Epoch: 51/80 | Validation loss: 0.3565 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_51.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 197\n",
      "Epoch: 52/80 | Train loss: 0.2149 | Train accuracy: 0.9219\n",
      "Epoch: 52/80 | Validation loss: 0.2799 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_52.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 187\n",
      "Epoch: 53/80 | Train loss: 0.2017 | Train accuracy: 0.9062\n",
      "Epoch: 53/80 | Validation loss: 0.2700 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_53.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 192\n",
      "Epoch: 54/80 | Train loss: 0.1613 | Train accuracy: 0.9219\n",
      "Epoch: 54/80 | Validation loss: 0.3051 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_54.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 199\n",
      "Epoch: 55/80 | Train loss: 0.2009 | Train accuracy: 0.9219\n",
      "Epoch: 55/80 | Validation loss: 0.2447 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_55.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 200\n",
      "Epoch: 56/80 | Train loss: 0.1750 | Train accuracy: 0.9219\n",
      "Epoch: 56/80 | Validation loss: 0.2642 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_56.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 200\n",
      "Epoch: 57/80 | Train loss: 0.1964 | Train accuracy: 0.9219\n",
      "Epoch: 57/80 | Validation loss: 0.2885 | Validation accuracy: 0.8750\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_57.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 189\n",
      "Epoch: 58/80 | Train loss: 0.1560 | Train accuracy: 0.9375\n",
      "Epoch: 58/80 | Validation loss: 0.2666 | Validation accuracy: 0.9375\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_58.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 192\n",
      "Epoch: 59/80 | Train loss: 0.2179 | Train accuracy: 0.8906\n",
      "Epoch: 59/80 | Validation loss: 0.2686 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_59.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 216\n",
      "Epoch: 60/80 | Train loss: 0.1814 | Train accuracy: 0.9062\n",
      "Epoch: 60/80 | Validation loss: 0.2493 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_60.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 190\n",
      "Epoch: 61/80 | Train loss: 0.1810 | Train accuracy: 0.9219\n",
      "Epoch: 61/80 | Validation loss: 0.3805 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_61.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 194\n",
      "Epoch: 62/80 | Train loss: 0.1590 | Train accuracy: 0.9219\n",
      "Epoch: 62/80 | Validation loss: 0.2534 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_62.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 223\n",
      "Epoch: 63/80 | Train loss: 0.2176 | Train accuracy: 0.9062\n",
      "Epoch: 63/80 | Validation loss: 0.2708 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_63.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 203\n",
      "Epoch: 64/80 | Train loss: 0.2191 | Train accuracy: 0.9062\n",
      "Epoch: 64/80 | Validation loss: 0.2933 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_64.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 198\n",
      "Epoch: 65/80 | Train loss: 0.1282 | Train accuracy: 0.9375\n",
      "Epoch: 65/80 | Validation loss: 0.2466 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_65.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 201\n",
      "Epoch: 66/80 | Train loss: 0.2472 | Train accuracy: 0.8906\n",
      "Epoch: 66/80 | Validation loss: 0.3887 | Validation accuracy: 0.8438\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_66.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 192\n",
      "Epoch: 67/80 | Train loss: 0.1298 | Train accuracy: 0.9531\n",
      "Epoch: 67/80 | Validation loss: 0.2969 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_67.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 206\n",
      "Epoch: 68/80 | Train loss: 0.1506 | Train accuracy: 0.9531\n",
      "Epoch: 68/80 | Validation loss: 0.2436 | Validation accuracy: 0.9219\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_68.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 194\n",
      "Epoch: 69/80 | Train loss: 0.1597 | Train accuracy: 0.9531\n",
      "Epoch: 69/80 | Validation loss: 0.2896 | Validation accuracy: 0.9375\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_69.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 187\n",
      "Epoch: 70/80 | Train loss: 0.1511 | Train accuracy: 0.9688\n",
      "Epoch: 70/80 | Validation loss: 0.2596 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_70.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 202\n",
      "Epoch: 71/80 | Train loss: 0.1079 | Train accuracy: 0.9531\n",
      "Epoch: 71/80 | Validation loss: 0.2417 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_71.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 203\n",
      "Epoch: 72/80 | Train loss: 0.1499 | Train accuracy: 0.9219\n",
      "Epoch: 72/80 | Validation loss: 0.2680 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_72.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 192\n",
      "Epoch: 73/80 | Train loss: 0.2149 | Train accuracy: 0.9062\n",
      "Epoch: 73/80 | Validation loss: 0.2273 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_73.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 191\n",
      "Epoch: 74/80 | Train loss: 0.1476 | Train accuracy: 0.9375\n",
      "Epoch: 74/80 | Validation loss: 0.2591 | Validation accuracy: 0.9062\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_74.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 201\n",
      "Epoch: 75/80 | Train loss: 0.1793 | Train accuracy: 0.9062\n",
      "Epoch: 75/80 | Validation loss: 0.2750 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_75.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 197\n",
      "Epoch: 76/80 | Train loss: 0.1004 | Train accuracy: 0.9688\n",
      "Epoch: 76/80 | Validation loss: 0.2376 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_76.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 188\n",
      "Epoch: 77/80 | Train loss: 0.1314 | Train accuracy: 0.9688\n",
      "Epoch: 77/80 | Validation loss: 0.3335 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_77.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 182\n",
      "Epoch: 78/80 | Train loss: 0.1194 | Train accuracy: 0.9688\n",
      "Epoch: 78/80 | Validation loss: 0.4063 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_78.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 179\n",
      "Epoch: 79/80 | Train loss: 0.0992 | Train accuracy: 0.9531\n",
      "Epoch: 79/80 | Validation loss: 0.3855 | Validation accuracy: 0.8906\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_79.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 180\n",
      "Epoch: 80/80 | Train loss: 0.1087 | Train accuracy: 0.9375\n",
      "Epoch: 80/80 | Validation loss: 0.3807 | Validation accuracy: 0.8594\n",
      "INFO:tensorflow:./model/fastTextgensim/fastText_review_sentiment_epoch_80.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Time: 200\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = g) as sess:\n",
    "    saver = tf.train.Saver(max_to_keep=None)\n",
    "    dt = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    logdir = \"tensorboard/\" + dt + \"/\"\n",
    "    writer = tf.summary.FileWriter(logdir, g)\n",
    "    writer_valid = tf.summary.FileWriter('tensorboard/'+ dt +'_valid', g)\n",
    "    writer_train = tf.summary.FileWriter('tensorboard/'+ dt +'_train', g)\n",
    "    iteration = 1\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        tic = datetime.now()\n",
    "        # Running train data\n",
    "        state = sess.run(init_state)\n",
    "        for batch_x_train, batch_y_train in mini_batches_train:\n",
    "            summary, c, _, state, a = sess.run([merged, cost, train_op, final_state, acc],\n",
    "                                     feed_dict = {'tf_x:0' : batch_x_train,\n",
    "                                                 'tf_y:0' : batch_y_train,\n",
    "                                                 init_state : state,\n",
    "                                                 tf_keep_prob : prob})\n",
    "\n",
    "            writer.add_summary(summary, iteration)\n",
    "            iteration +=1\n",
    "        writer_train.add_summary(summary, epoch+1)\n",
    "        print(\"Epoch: {0}/{1} | Train loss: {2:.4f} | Train accuracy: {3:.4f}\".format(epoch+1, \n",
    "                                                                                      n_epochs, \n",
    "                                                                                      c, \n",
    "                                                                                      a))\n",
    "        # Running validation data\n",
    "        valid_state = sess.run(init_state)\n",
    "        for batch_x_valid, batch_y_valid in mini_batches_valid:\n",
    "            summary, c_valid, valid_state, a_valid = sess.run([merged, cost, final_state, acc],\n",
    "                                     feed_dict = {'tf_x:0' : batch_x_valid,\n",
    "                                                 'tf_y:0' : batch_y_valid,\n",
    "                                                 init_state : valid_state,\n",
    "                                                 tf_keep_prob : 1})\n",
    "        writer_valid.add_summary(summary, epoch+1)\n",
    "        print(\"Epoch: {0}/{1} | Validation loss: {2:.4f} | Validation accuracy: {3:.4f}\".format(epoch+1, \n",
    "                                                                                                n_epochs, \n",
    "                                                                                                c_valid, \n",
    "                                                                                                a_valid))\n",
    "        # Save model every epoch\n",
    "        saver.save(sess,\"./model/fastTextgensim/fastText_review_sentiment_epoch_{}.ckpt\".format(epoch+1))\n",
    "        \n",
    "        toc = datetime.now()\n",
    "        time = (toc - tic)\n",
    "        print(\"Time: {}\".format(time.seconds))\n",
    "writer.close()\n",
    "writer_train.close()\n",
    "writer_valid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training accuracy and loss via TensorBoard\n",
    "\n",
    "TensorBoard for Accuracy and the Loss during the training time after 80 epochs. \n",
    "\n",
    "\n",
    "![](./images/ft_acc.png)\n",
    "\n",
    "\n",
    "![](./images/ft_cost.png)\n",
    "\n",
    "Below is our graph for detecting over-fitting during training. We will pick model 37 as our last model.\n",
    "\n",
    "- <span style=\"color:rgb(70,173,193)\">Blue line </span>: training cost\n",
    "- <span style=\"color:rgb(173,73,190)\">Purple line</span>: validation cost\n",
    "\n",
    "![](./images/ft_trvd_cost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 86.9960\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = g) as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    accuracy = []\n",
    "    saver.restore(sess, './data/model/fastTextgensim/fastText_review_sentiment_epoch_37.ckpt')\n",
    "    test_state = sess.run(init_state)\n",
    "    for batch_x, batch_y in mini_batches_test:\n",
    "        feed = {'tf_x:0': batch_x, \n",
    "            'tf_y:0': batch_y,\n",
    "            'keep_prob:0' : 1, \n",
    "            init_state : test_state}\n",
    "        a, test_state = sess.run([acc, final_state], feed_dict=feed)\n",
    "        accuracy.append(a)\n",
    "    print(\"Overall accuracy: {0:.4f}\".format(np.mean(accuracy)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with our own review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Same reviews will be used to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_review_neg = \"Content is very boring and this is a waste of time to see it.\"\n",
    "str_review_pos = \"Movie is about a spy, which is not new subject. Content is very good and this is a great time to see it.\"\n",
    "user_review_neg = format_user_review(train_review = str_review_neg, batch_size = 64,  max_seq_len = 230, word_list = load_word_list)\n",
    "user_review_pos = format_user_review(train_review = str_review_pos, batch_size = 64,  max_seq_len = 230, word_list = load_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with negative review first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a negative review.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = g) as sess:\n",
    "    saver.restore(sess, './data/model/fastTextgensim/fastText_review_sentiment_epoch_37.ckpt')\n",
    "    own_state = sess.run(init_state)\n",
    "    \n",
    "    feed = {'tf_x:0': user_review_neg,\n",
    "            'keep_prob:0' : 1,\n",
    "            init_state : own_state}\n",
    "    \n",
    "    lbl, own_state = sess.run(['labels:0', final_state], feed_dict=feed)\n",
    "    if lbl[-1] == 0:\n",
    "        print(\"This is a negative review.\")\n",
    "    else:\n",
    "        print(\"This is a positive review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With positive review :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a positive review.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = g) as sess:\n",
    "    saver.restore(sess, './data/model/fastTextgensim/fastText_review_sentiment_epoch_37.ckpt')\n",
    "    own_state = sess.run(init_state)\n",
    "    \n",
    "    feed = {'tf_x:0': user_review_pos,\n",
    "            'keep_prob:0' : 1,\n",
    "            init_state : own_state}\n",
    "    \n",
    "    lbl, own_state = sess.run(['labels:0', final_state], feed_dict=feed)\n",
    "    if lbl[-1] == 0:\n",
    "        print(\"This is a negative review.\")\n",
    "    else:\n",
    "        print(\"This is a positive review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of our notebook. For more information please kindly check inside the report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
