# Context 
The main purpose of this work is to understand about the word embedding (part of language modelling techniques for NLP), its applications, and how to build a model that can be used for text processing with the help of some related Deep Learning packages/libraries for NLP. 

# Theoretical:
* What is word embedding for text, RNN
* Algorithms used for learning word embedding from text data (eg. fasttext, glove,  word2vec developed byÂ Mikolov et al that is used for learning vector representations of words)
* Some insights about Deep learning packages (eg. TensorFlow)
# Practical: 
Apply word embedding in deep learning (Python) (dataset can be chosen from Kaggle)

# Setup:
To run the project, please download the data zip file and extract it into folder name `data`, put it into the same place with other Jupyter Notebooks.

Link: https://drive.google.com/drive/folders/13UluRzWGIraS9ugfuS2qdz3JKxS5etTn?usp=sharing

